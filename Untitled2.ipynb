{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85023503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "train_data.info()\n",
    "\n",
    "test_data.info()\n",
    "\n",
    "train_data.dropna().head()\n",
    "\n",
    "train_data['target'].value_counts()\n",
    "\n",
    "null_values = train_data.isnull().sum()\n",
    "for index in range(len(train_data.columns)):\n",
    "    if null_values[index] > 0:\n",
    "        print('{:.2f}% ({}) Null Values Present in \"{}\" Feature'.format(null_values[index]/len(train_data)*100,\n",
    "                                                              null_values[index], train_data.columns[index]))\n",
    "\n",
    "train_data['keyword'].fillna(method = 'backfill', inplace = True)\n",
    "train_data['keyword'].fillna(method = 'ffill', inplace = True)\n",
    "test_data['keyword'].fillna(method = 'backfill', inplace = True)\n",
    "test_data['keyword'].fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "test_data['keyword'].value_counts()\n",
    "\n",
    "def decontration(text):\n",
    "    text = re.sub(r\"aren't\", 'are not', text)\n",
    "    text = re.sub(r\"won't\", 'will not', text)\n",
    "    text = re.sub(r\"doesn't\", 'does not', text)\n",
    "    \n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text.lower()\n",
    "\n",
    "def cleaning_text(text):\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    text = decontration(text)\n",
    "    text  = re.sub('[^A-Za-z,0123]+', ' ', text)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_list = [word for word in text.split() if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(processed_list)\n",
    "\n",
    "preprocessed_text = []\n",
    "for text in tqdm(train_data['text']):\n",
    "    preprocessed_text.append(cleaning_text(text))\n",
    "train_data['text'] = preprocessed_text\n",
    "\n",
    "preprocessed_text = []\n",
    "for text in tqdm(test_data['text']):\n",
    "    preprocessed_text.append(cleaning_text(text))\n",
    "test_data['text'] = preprocessed_text\n",
    "\n",
    "train_data['keyword']\n",
    "\n",
    "X = train_data[['keyword', 'text']]\n",
    "y = train_data['target']\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "X_train\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=3)\n",
    "X_train_text = vectorizer.fit_transform(X_train['text'])\n",
    "X_test_text = vectorizer.transform(X_test['text'])\n",
    "test_text = vectorizer.transform(test_data['text']) \n",
    "\n",
    "print(\"Vectorized Training Text Data Shape    : \", X_train_text.shape)\n",
    "print(\"Vectorized Testing Text Data Shape     : \", X_test_text.shape)\n",
    "print(\"Vectorized Real Testing Text Shape     : \", test_text.shape)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_keyword = vectorizer.fit_transform(X_train['keyword'])\n",
    "X_test_keyword = vectorizer.transform(X_test['keyword']) \n",
    "test_keyword = vectorizer.transform(test_data['keyword']) \n",
    "\n",
    "print(\"Vectorized Training Data Shape    : \", X_train_keyword.shape)\n",
    "print(\"Vectorized Testing Data Shape     : \", X_test_keyword.shape)\n",
    "print(\"Vectorized Testing Data Shape     : \", test_keyword.shape)\n",
    "\n",
    "print(X_train_keyword)\n",
    "\n",
    "X_train_final = np.hstack((X_train_text.toarray(), X_train_keyword.toarray()))\n",
    "X_test_final = np.hstack((X_test_text.toarray(), X_test_keyword.toarray()))\n",
    "testing_data = np.hstack((test_text.toarray(), test_keyword.toarray()))\n",
    "\n",
    "X_test_final.shape\n",
    "\n",
    "parameters = {'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "sgd_clf = SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=910)\n",
    "clf = GridSearchCV(sgd_clf, parameters, n_jobs = -1, cv = 5, scoring = make_scorer(f1_score))\n",
    "clf.fit(X_train_final, y_train)\n",
    "clf.best_params_\n",
    "\n",
    "sgd_clf = SGDClassifier(alpha = 0.001, class_weight='balanced', penalty='l2', loss='log', random_state=910)\n",
    "sgd_clf.fit(X_train_final, y_train)\n",
    "\n",
    "train_preds = sgd_clf.predict(X_train_final)\n",
    "test_preds = sgd_clf.predict(X_test_final)\n",
    "\n",
    "print(\"Train Score \", f1_score(y_train, train_preds))\n",
    "print('Test Score ', f1_score(y_test, test_preds))\n",
    "\n",
    "submission_file = pd.DataFrame({'id':test_data['id'], 'target':sgd_clf.predict(testing_data)})\n",
    "submission_file.to_csv(\"submission_file.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
